{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tut.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyashdamle/deep_learning_projects/blob/master/pytorch_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4uV9PSPSoe",
        "colab_type": "text"
      },
      "source": [
        "# NOTES:\n",
        "- Memory is shared between np and torch arrays, after inter-conversions - a change in one reflects in other\n",
        "- **IMP:  Underscores (' _ ')  represent in-place ops**\n",
        "-  The first dimension could be keprt the batch_size. Then,\n",
        "    - W1 : ip_features X n_hidden_1\n",
        "    - W2 : n_hidden_1 X n_hidden_2 & so on...\n",
        "- AutoGrad keeps track of outputs of the **leaf nodes only** - in this case, only weights and biases: [look this up](https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95)\n",
        "- Be careful with the leaf variables:\n",
        "  - They should not be overwritten by other objects (ie, ops such as W1 = W1 - lr*grad)\n",
        "  - In-place ops are NOT allowed over them\n",
        "  - So, just use the '.data'  notation to replace values during update operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_24a0APNNHiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2idHzlOeNbEu",
        "colab_type": "code",
        "outputId": "f9f18349-2a8e-455f-88c7-7cf80f6e491d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk74BjHTG7W",
        "colab_type": "text"
      },
      "source": [
        "# Simple Feed-Forward net from scratch using AutoGrad feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hoQPBg-Tlgg",
        "colab_type": "code",
        "outputId": "40172b22-3180-4445-9bd4-2a927c6fc669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "trainset = datasets.MNIST('data/',download = True, train= True, transform=transforms.ToTensor())                 #convert images to tensors\n",
        "testset = datasets.MNIST('data/',download = True, train= False, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(trainset,batch_size = 100, shuffle=True)\n",
        "data_iter = iter(loader)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 9056570.46it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 135748.48it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2244510.10it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 51017.29it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epwWjAZ8UG2H",
        "colab_type": "code",
        "outputId": "cdec376b-2e60-446c-f124-f6383f91e7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "images,labels = data_iter.next()\n",
        "print(images.shape)\n",
        "plt.imshow(images[0].numpy().squeeze(),cmap='gray')\n",
        "plt.show()\n",
        "print(labels[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRY8W8ZhWUhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the weights\n",
        "W1 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(784,300)),requires_grad=True,dtype=torch.float)\n",
        "B1 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,300)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "W2 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(300,100)), requires_grad=True,dtype=torch.float)\n",
        "B2 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,100)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "W3 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(100,10)), requires_grad=True,dtype=torch.float)\n",
        "B3 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,10)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "\n",
        "lr = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu3M1YPkZW4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_pass(X):\n",
        "  X = X.view(-1,784)\n",
        "  h1 = torch.tanh(torch.mm(X,W1)+B1)     # batch_size X n_hidden_1\n",
        "  h2 = torch.tanh(torch.mm(h1,W2)+B2)    # batch_size X n_hidden_2\n",
        "  o = torch.tanh(torch.mm(h2,W3)+B3)     # batch_size X n_output\n",
        "  \n",
        "  # softmax\n",
        "  d_r = torch.sum(torch.exp(o),dim=1)    # the denominator: size(50,)\n",
        "  d_r = d_r.view(-1,1)                   # one sum - per row\n",
        "  logits = torch.exp(o)/d_r \n",
        "  return logits\n",
        "\n",
        "def backward_pass(logits,y):\n",
        "  global W1, W2, B1, B2, W3, B3\n",
        "  \n",
        "  # --- get cross-entropy loss ---\n",
        "  \n",
        "  # convert y into one-hot encodings\n",
        "  src = torch.ones_like(logits)\n",
        "  y_one_hot = torch.zeros_like(logits)\n",
        "  y_one_hot = torch.scatter(y_one_hot,1, y.view(-1,1), src)\n",
        "  \n",
        "  # in cross-entropy loss, taking mean of errors of all datapoints in this mini-batch\n",
        "  loss = -1*(y_one_hot*torch.log(logits) + (1-y_one_hot)*torch.log(1-logits)).sum(1).mean()\n",
        "  \n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "  \n",
        "  # update the weights and biases accordingly\n",
        "  # NOTE: directly using mathematical operations would overwrite variables - they would not be leaves anymore\n",
        "  # NOTE: leaf variables could not be directly operated upon\n",
        "  # Using the average of the gradient over the batch\n",
        "\n",
        "  W1.data = W1.sub(lr*W1.grad.data).data\n",
        "  B1.data = B1.sub(lr*B1.grad.data).data\n",
        "  W2.data = W2.sub(lr*W2.grad.data).data\n",
        "  B2.data = B2.sub(lr*B2.grad.data).data\n",
        "  W3.data = W3.sub(lr*W3.grad.data).data\n",
        "  B3.data = B3.sub(lr*B3.grad.data).data\n",
        "  return  loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LBJYUgKahYn",
        "colab_type": "code",
        "outputId": "b462e5a5-11f3-42bc-a2bd-850c338f7573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "display_step = 1\n",
        "lr_update_step = 2\n",
        "\n",
        "for ep in range(10):\n",
        "  if ep%lr_update_step == 0:\n",
        "    lr = lr/2.0\n",
        "  data_iter = iter(loader)                 # resetting the iterator\n",
        "  for images,labels in data_iter:          # a mini-batch\n",
        "    logits= forward_pass(images)           # getting the probs\n",
        "    loss = backward_pass(logits, labels)   # updating weights for this mini-batch\n",
        "  if ep%display_step == 0:\n",
        "    print(\"Epoch # %d: Loss: %f\"%(ep, loss.data))\n",
        "    \n",
        "# print a sample of labels and predictions to get a feel\n",
        "print(logits.argmax(dim=1))\n",
        "print(labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch # 0: Loss: 2.122714\n",
            "Epoch # 1: Loss: 1.891296\n",
            "Epoch # 2: Loss: 1.903538\n",
            "Epoch # 3: Loss: 1.859159\n",
            "Epoch # 4: Loss: 1.738800\n",
            "Epoch # 5: Loss: 1.771342\n",
            "Epoch # 6: Loss: 1.927214\n",
            "Epoch # 7: Loss: 1.840003\n",
            "Epoch # 8: Loss: 1.756873\n",
            "Epoch # 9: Loss: 1.623204\n",
            "tensor([4, 9, 0, 2, 9, 8, 4, 3, 0, 6, 8, 1, 0, 6, 1, 4, 8, 3, 5, 0, 1, 3, 0, 0,\n",
            "        6, 9, 1, 9, 1, 6, 1, 1, 6, 6, 6, 4, 5, 9, 4, 8, 9, 2, 1, 1, 4, 9, 9, 8,\n",
            "        8, 3, 9, 9, 1, 2, 1, 1, 6, 9, 5, 2, 4, 5, 8, 3, 4, 5, 1, 2, 1, 0, 1, 1,\n",
            "        1, 8, 2, 5, 0, 1, 8, 2, 7, 1, 6, 4, 1, 5, 5, 1, 1, 9, 8, 9, 8, 9, 9, 6,\n",
            "        4, 7, 3, 3])\n",
            "tensor([4, 7, 0, 2, 4, 8, 4, 3, 0, 6, 8, 1, 2, 6, 1, 4, 8, 3, 5, 0, 1, 3, 0, 0,\n",
            "        6, 7, 1, 7, 1, 6, 1, 1, 6, 6, 6, 6, 5, 9, 9, 8, 7, 2, 1, 1, 4, 7, 7, 8,\n",
            "        8, 3, 5, 4, 1, 2, 1, 1, 6, 4, 5, 2, 4, 0, 8, 3, 4, 5, 1, 5, 1, 0, 1, 1,\n",
            "        1, 8, 3, 5, 0, 1, 8, 2, 1, 1, 6, 4, 1, 5, 3, 1, 1, 7, 8, 4, 8, 7, 7, 6,\n",
            "        4, 7, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-hfiK3XXwt6",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Training Neural Net using the torch.nn and torch.optim API on FashionMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPFrhT5SO75T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100\n",
        "trainset = datasets.FashionMNIST('data/',download = True, train= True, transform=transforms.ToTensor())\n",
        "testset = datasets.FashionMNIST('data/',download = True, train= False, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(trainset,batch_size = batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QRtqHsSY9zi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "6343429e-e70f-4a03-b836-87a526ac078a"
      },
      "source": [
        "images,labels = iter(loader).next()\n",
        "print(images.shape)\n",
        "plt.imshow(images[0].numpy().squeeze(),cmap='gray')\n",
        "plt.show()\n",
        "print(labels[0])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztI8WcYVZK6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GUKe_zoZANX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5c0e960e-a023-4e14-a256-c8e6886b223d"
      },
      "source": [
        "# creating a class derived from the module class- supports forward() and backward() itself\n",
        "model = nn.Sequential(nn.Linear(784,300),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(300,100),\n",
        "                     nn.ReLU(),\n",
        "                     nn.Linear(100,10),\n",
        "                     nn.ReLU())\n",
        "\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "opt = optim.SGD(model.parameters(), lr = 0.01, dampening=0.7)\n",
        "n_epochs = 10\n",
        "for ep in range(n_epochs):\n",
        "  for imgs, labels in loader:\n",
        "    imgs = imgs.view(batch_size,-1) # reshape the data\n",
        "    opt.zero_grad()                 # reset gradients\n",
        "    logits =  model.forward(imgs)   # do forward pass\n",
        "    loss =  loss_fn(logits, labels) # get loss\n",
        "    loss.backward()                 # collect gradients in backward pass\n",
        "    opt.step()                      # update params\n",
        "  print(\"Epoch # %d: Loss: %f\"%(ep, loss.data))\n",
        "  \n",
        "  \n",
        "# print a sample of labels and predictions to get a feel\n",
        "print(logits.argmax(dim=1))\n",
        "print(labels)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch # 0: Loss: 1.688304\n",
            "Epoch # 1: Loss: 1.059809\n",
            "Epoch # 2: Loss: 0.736252\n",
            "Epoch # 3: Loss: 0.742365\n",
            "Epoch # 4: Loss: 0.867676\n",
            "Epoch # 5: Loss: 0.768756\n",
            "Epoch # 6: Loss: 0.615788\n",
            "Epoch # 7: Loss: 0.770842\n",
            "Epoch # 8: Loss: 0.664202\n",
            "Epoch # 9: Loss: 0.648217\n",
            "tensor([7, 8, 5, 1, 1, 5, 9, 8, 1, 2, 6, 3, 3, 3, 5, 0, 0, 0, 9, 8, 5, 6, 8, 8,\n",
            "        1, 2, 0, 2, 9, 7, 3, 3, 6, 3, 6, 8, 8, 7, 2, 9, 1, 7, 0, 3, 7, 0, 0, 0,\n",
            "        2, 9, 2, 5, 0, 6, 5, 6, 5, 3, 6, 5, 7, 7, 9, 7, 0, 5, 3, 6, 3, 0, 2, 8,\n",
            "        5, 5, 6, 6, 1, 0, 0, 9, 5, 6, 1, 2, 8, 0, 8, 5, 9, 9, 5, 0, 2, 6, 7, 2,\n",
            "        2, 0, 6, 0])\n",
            "tensor([7, 8, 5, 1, 1, 5, 9, 8, 1, 2, 2, 3, 3, 3, 7, 6, 6, 0, 4, 8, 5, 2, 8, 8,\n",
            "        1, 2, 0, 2, 9, 7, 2, 3, 6, 3, 4, 8, 8, 7, 2, 9, 3, 7, 0, 4, 7, 0, 0, 0,\n",
            "        6, 9, 4, 5, 0, 0, 5, 6, 5, 3, 6, 7, 7, 7, 9, 7, 0, 5, 6, 6, 3, 0, 2, 8,\n",
            "        5, 5, 6, 6, 1, 3, 0, 9, 5, 4, 1, 4, 8, 6, 8, 5, 9, 9, 5, 0, 2, 4, 7, 2,\n",
            "        2, 0, 4, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BwTrVc1buX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}