{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tut.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suyashdamle/deep_learning_projects/blob/master/pytorch_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_24a0APNNHiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2idHzlOeNbEu",
        "colab_type": "code",
        "outputId": "a7fd95f3-9612-469f-81ee-fb74fd17909c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ4uV9PSPSoe",
        "colab_type": "text"
      },
      "source": [
        "# NOTES:\n",
        "- Memory is shared between np and torch arrays, after inter-conversions - a change in one reflects in other\n",
        "- **IMP:  Underscores (' _ ')  represent in-place ops**\n",
        "-  The first dimension could be keprt the batch_size. Then,\n",
        "    - W1 : ip_features X n_hidden_1\n",
        "    - W2 : n_hidden_1 X n_hidden_2 & so on...\n",
        "- AutoGrad keeps track of outputs of the **leaf nodes only** - in this case, only weights and biases: [look this up](https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95)\n",
        "- Be careful with the leaf variables:\n",
        "  - They should not be overwritten by other objects (ie, ops such as W1 = W1 - lr*grad)\n",
        "  - In-place ops are NOT allowed over them\n",
        "  - So, just use the '.data'  notation to replace values during update operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhk74BjHTG7W",
        "colab_type": "text"
      },
      "source": [
        "# Simple Feed-Forward net from scratch using AutoGrad feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOEojxYPPlyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hoQPBg-Tlgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "378d10d1-113b-4232-fd33-612ddd61757b"
      },
      "source": [
        "trainset = datasets.MNIST('data/',download = True, train= True, transform=transforms.ToTensor())                 #convert images to tensors\n",
        "testset = datasets.MNIST('data/',download = True, train= False, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(trainset,batch_size = 100, shuffle=True)\n",
        "data_iter = iter(loader)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20671408.31it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 316144.21it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5082206.04it/s]                           \n",
            "8192it [00:00, 128232.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epwWjAZ8UG2H",
        "colab_type": "code",
        "outputId": "f2d8a03e-4b6b-4dd8-8323-0667dbafd6d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "images,labels = data_iter.next()\n",
        "print(images.shape)\n",
        "plt.imshow(images[0].numpy().squeeze(),cmap='gray')\n",
        "plt.show()\n",
        "print(labels[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADXpJREFUeJzt3X2IVXUex/HPd9v8IwtyiibxoQeR\npRCyZSpJWVx6oI3AHsgSWlyQpj8KNuiPJIP1z9rMyiBjJMmitNBCodgeZKFdWKqxXLNMa2M0xcbK\nUIuiTb/7xxzbqeb+zvWec+654/f9gmHuPd/z8OXix3PunIefubsAxPOruhsAUA/CDwRF+IGgCD8Q\nFOEHgiL8QFCEHwiK8ANBEX4gqF+3c2NmxuWEQMXc3ZqZr9Ce38yuMrPtZvaxmS0ssi4A7WWtXttv\nZidI2iHpCkm7Jb0taZ67f5BYhj0/ULF27PkvlvSxu3/i7t9LWiNpToH1AWijIuGfIOnTYe93Z9N+\nwsx6zazfzPoLbAtAySr/g5+790nqkzjsBzpJkT3/HkmThr2fmE0DMAoUCf/bkqaa2TlmNkbSzZI2\nlNMWgKq1fNjv7j+Y2R2SXpF0gqSV7v5+aZ0BqFTLp/pa2hjf+YHKteUiHwCjF+EHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I\nivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBtTxEtySZ2YCkQ5IOS/rB3XvKaApA9QqF\nP/N7d/+ihPUAaCMO+4GgiobfJb1qZpvMrLeMhgC0R9HD/lnuvsfMzpD0mpl96O5vDJ8h+0+B/xiA\nDmPuXs6KzBZL+trdlyTmKWdjABpyd2tmvpYP+81srJmdcvS1pCslbW11fQDaq8hhf7ekF83s6Hqe\ndfe/ldIVgMqVdtjf1MY47B91uru7k/UpU6Yk688++2zD2uTJk5PLLl26NFl/4IEHkvXBwcFk/XhV\n+WE/gNGN8ANBEX4gKMIPBEX4gaAIPxAUp/qOc2PHjk3WL7jggmR97dq1yfq4ceOS9TFjxiTrReSd\nykudKlyypOGFqKMep/oAJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFBlPL0XHWzFihXJ+k033ZSs79+/\nP1lftmxZsn7mmWc2rN1yyy3JZfOk1i1Jp512WqH1H+/Y8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxA\nUJznHwXy7slPncu/8cYbk8s+9thjyfq9996brB84cCBZX7NmTbJexDfffJOsr1q1qrJtHw/Y8wNB\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAULnn+c1spaRrJO1z92nZtC5Jz0k6W9KApLnu/lV1bca2cOHC\nZD11T/7rr7+eXHbRokXJ+sGDB5P1U089NVm/7LLLkvUinn/++WT9ww8/rGzbx4Nm9vxPSrrqZ9MW\nStro7lMlbczeAxhFcsPv7m9I+vnjXOZIOnr51CpJ15bcF4CKtfqdv9vd92avP5PUXVI/ANqk8LX9\n7u6pMfjMrFdSb9HtAChXq3v+QTMbL0nZ732NZnT3PnfvcfeeFrcFoAKthn+DpPnZ6/mS1pfTDoB2\nyQ2/ma2W9C9JvzGz3Wa2QNJ9kq4ws48kXZ69BzCK5H7nd/d5DUrVncANZvv27cn61KlTk/VHH320\nYe3uu+9OLvvdd98l63lmz56drBd5dv7g4GCyfv/997e8bnCFHxAW4QeCIvxAUIQfCIrwA0ERfiAo\nHt3dBnm3veadynvllVeS9dRtuUVP5U2cODFZzzvd5t7wyu9ca9euTdZ37NjR8rrBnh8Ii/ADQRF+\nICjCDwRF+IGgCD8QFOEHgrIi52GPeWOJx32NZnnnwt99991kPe+21/POOy9Zz7slOOWss85K1p9+\n+ulkfebMmS1v+9ChQ8n6jBkzknUezT0yd7dm5mPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcT9/\nCfIeX93V1ZWsDwwMJOuff/75MXb0f2eccUayvnjx4mR91qxZyXqR60RSQ4tLnMevGnt+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwgq9zy/ma2UdI2kfe4+LZu2WNKtko6egL7H3V+uqslON23atELL79mz\nJ1nfv39/sn755Zc3rC1fvjy57LnnnpusV6m/v7+2baO5Pf+Tkq4aYfpD7j49+wkbfGC0yg2/u78h\nKb3rATDqFPnOf4eZbTGzlWY2rrSOALRFq+FfLmmKpOmS9kp6sNGMZtZrZv1mxhc8oIO0FH53H3T3\nw+5+RNIKSRcn5u1z9x5372m1SQDlayn8ZjZ+2NvrJG0tpx0A7dLMqb7VkmZLOt3Mdkv6i6TZZjZd\nkksakHRbhT0CqEBu+N193giTn6igl1HLLP2Y9Lx63j3zR44cOeaeypLXe57169c3rH355ZeF1o1i\nuMIPCIrwA0ERfiAowg8ERfiBoAg/EBSP7i7BkiVLkvVLL700Wc8b5jrv8dgHDx5sWNu2bVty2Usu\nuSRZz3P48OFkffXq1YXWj+qw5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKzIEMvHvDGz9m2sg0ye\nPDlZnz59eqH1v/XWWw1rN9xwQ3LZZcuWJet5t/Ru2rQpWb/ooouSdZTP3Zu6D5s9PxAU4QeCIvxA\nUIQfCIrwA0ERfiAowg8Exf38bbBr165C9SKuv/76ytYtSS+88EKl60d12PMDQRF+ICjCDwRF+IGg\nCD8QFOEHgiL8QFC55/nNbJKkpyR1S3JJfe7+iJl1SXpO0tmSBiTNdfevqmsVjSxYsKBhLW9MgDxb\ntmxJ1h9++OFC60d9mtnz/yDpLnc/X9IMSbeb2fmSFkra6O5TJW3M3gMYJXLD7+573f2d7PUhSdsk\nTZA0R9KqbLZVkq6tqkkA5Tum7/xmdrakCyW9Kanb3fdmpc809LUAwCjR9LX9ZnaypHWS7nT3g8Of\n7ebu3uj5fGbWK6m3aKMAytXUnt/MTtRQ8J9x96N3cgya2fisPl7SvpGWdfc+d+9x954yGgZQjtzw\n29Au/glJ29x96bDSBknzs9fzJa0vvz0AVWnmsH+mpD9Kes/MNmfT7pF0n6TnzWyBpJ2S5lbTIvJ0\ndXU1rI0ZM6bQuk866aRkPW/93377baHtozq54Xf3f0pq9Bzwy8ptB0C7cIUfEBThB4Ii/EBQhB8I\nivADQRF+ICge3X0c2LlzZ8Na0SHYly9fnqwfOHCg0PpRH/b8QFCEHwiK8ANBEX4gKMIPBEX4gaAI\nPxAU5/mPA/Pmzats3evWrats3agXe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrz/EjatWtX3S2g\nIuz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCo3PP8ZjZJ0lOSuiW5pD53f8TMFku6VdLn2az3uPvL\nVTWKxh5//PGGta6uruSyL730UtntYJRo5iKfHyTd5e7vmNkpkjaZ2WtZ7SF3X1JdewCqkht+d98r\naW/2+pCZbZM0oerGAFTrmL7zm9nZki6U9GY26Q4z22JmK81sXINles2s38z6C3UKoFRNh9/MTpa0\nTtKd7n5Q0nJJUyRN19CRwYMjLefufe7e4+49JfQLoCRNhd/MTtRQ8J9x9xckyd0H3f2wux+RtELS\nxdW1CaBsueE3M5P0hKRt7r502PTxw2a7TtLW8tsDUBXLG8LZzGZJ+oek9yQdySbfI2mehg75XdKA\npNuyPw6m1lVsvGgAudzdmpkvN/xlIvxA9ZoNP1f4AUERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I\nivADQRF+ICjCDwRF+IGgCD8QFOEHgmr3EN1fSNo57P3p2bRO1Km9dWpfEr21qszezmp2xrbez/+L\njZv1d+qz/Tq1t07tS6K3VtXVG4f9QFCEHwiq7vD31bz9lE7trVP7kuitVbX0Vut3fgD1qXvPD6Am\ntYTfzK4ys+1m9rGZLayjh0bMbMDM3jOzzXUPMZYNg7bPzLYOm9ZlZq+Z2UfZ7xGHSaupt8Vmtif7\n7Dab2dU19TbJzP5uZh+Y2ftm9udseq2fXaKvWj63th/2m9kJknZIukLSbklvS5rn7h+0tZEGzGxA\nUo+7135O2Mx+J+lrSU+5+7Rs2l8l7Xf3+7L/OMe5+90d0ttiSV/XPXJzNqDM+OEjS0u6VtKfVONn\nl+hrrmr43OrY818s6WN3/8Tdv5e0RtKcGvroeO7+hqT9P5s8R9Kq7PUqDf3jabsGvXUEd9/r7u9k\nrw9JOjqydK2fXaKvWtQR/gmSPh32frc6a8hvl/SqmW0ys966mxlB97CRkT6T1F1nMyPIHbm5nX42\nsnTHfHatjHhdNv7g90uz3P23kv4g6fbs8LYj+dB3tk46XdPUyM3tMsLI0j+q87NrdcTrstUR/j2S\nJg17PzGb1hHcfU/2e5+kF9V5ow8PHh0kNfu9r+Z+ftRJIzePNLK0OuCz66QRr+sI/9uSpprZOWY2\nRtLNkjbU0McvmNnY7A8xMrOxkq5U540+vEHS/Oz1fEnra+zlJzpl5OZGI0ur5s+u40a8dve2/0i6\nWkN/8f+PpEV19NCgr3Ml/Tv7eb/u3iSt1tBh4H819LeRBZJOk7RR0keSXpfU1UG9Pa2h0Zy3aCho\n42vqbZaGDum3SNqc/Vxd92eX6KuWz40r/ICg+IMfEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg\n/gdZ2kDj0GNP0wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRY8W8ZhWUhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining the weights\n",
        "W1 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(784,300)),requires_grad=True,dtype=torch.float)\n",
        "B1 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,300)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "W2 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(300,100)), requires_grad=True,dtype=torch.float)\n",
        "B2 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,100)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "W3 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(100,10)), requires_grad=True,dtype=torch.float)\n",
        "B3 = torch.tensor(np.random.normal(loc = 0., scale=0.01, size=(1,10)),requires_grad = True,dtype=torch.float)\n",
        "\n",
        "\n",
        "lr = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu3M1YPkZW4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def forward_pass(X):\n",
        "  X = X.view(-1,784)\n",
        "  h1 = torch.tanh(torch.mm(X,W1)+B1)     # batch_size X n_hidden_1\n",
        "  h2 = torch.tanh(torch.mm(h1,W2)+B2)    # batch_size X n_hidden_2\n",
        "  o = torch.tanh(torch.mm(h2,W3)+B3)     # batch_size X n_output\n",
        "  \n",
        "  # softmax\n",
        "  d_r = torch.sum(torch.exp(o),dim=1)    # the denominator: size(50,)\n",
        "  d_r = d_r.view(-1,1)                   # one sum - per row\n",
        "  logits = torch.exp(o)/d_r \n",
        "  return logits\n",
        "\n",
        "def backward_pass(logits,y):\n",
        "  global W1, W2, B1, B2, W3, B3\n",
        "  \n",
        "  # get cross-entropy loss\n",
        "  loss = loss_fn(logits, y)\n",
        "  # calculate the gradients\n",
        "  loss.backward()\n",
        "  \n",
        "  # update the weights and biases accordingly\n",
        "  # NOTE: directly using mathematical operations would overwrite variables - they would not be leaves anymore\n",
        "  # NOTE: leaf variables could not be directly operated upon\n",
        "  # Using the average of the gradient over the batch\n",
        "\n",
        "  W1.data = W1.sub(lr*W1.grad.data).data\n",
        "  B1.data = B1.sub(lr*B1.grad.data).data\n",
        "  W2.data = W2.sub(lr*W2.grad.data).data\n",
        "  B2.data = B2.sub(lr*B2.grad.data).data\n",
        "  W3.data = W3.sub(lr*W3.grad.data).data\n",
        "  B3.data = B3.sub(lr*B3.grad.data).data\n",
        "  return  loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LBJYUgKahYn",
        "colab_type": "code",
        "outputId": "fee9d074-7bdf-451d-ab5c-d7713951c888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "display_step = 5\n",
        "for ep in range(20):\n",
        "  data_iter = iter(loader)                 # resetting the iterator\n",
        "  for images,labels in data_iter:          # a mini-batch\n",
        "    logits= forward_pass(images)           # getting the probs\n",
        "    loss = backward_pass(logits, labels)   # updating weights for this mini-batch\n",
        "  if ep%display_step == 0:\n",
        "    print(\"Epoch # %d: Loss: %f\"%(ep, loss.data))\n",
        "    \n",
        "# print a sample of labels and predictions to get a feel\n",
        "print(logits.argmax(dim=1))\n",
        "print(labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch # 0: Loss: 2.153310\n",
            "Epoch # 5: Loss: 2.049981\n",
            "Epoch # 10: Loss: 2.036253\n",
            "Epoch # 15: Loss: 2.034521\n",
            "tensor([9, 5, 9, 8, 9, 9, 3, 9, 0, 0, 4, 5, 1, 1, 3, 5, 0, 3, 9, 9, 2, 1, 2, 8,\n",
            "        5, 9, 5, 2, 2, 1, 1, 5, 9, 5, 2, 1, 9, 6, 9, 5, 1, 9, 9, 5, 2, 9, 6, 3,\n",
            "        6, 9, 3, 8, 9, 9, 9, 1, 4, 3, 9, 4, 9, 2, 3, 4, 1, 5, 4, 2, 9, 2, 5, 3,\n",
            "        5, 6, 9, 1, 1, 9, 4, 9, 7, 6, 8, 1, 3, 6, 5, 5, 2, 5, 1, 2, 3, 4, 9, 6,\n",
            "        8, 2, 9, 4])\n",
            "tensor([9, 5, 4, 5, 7, 4, 3, 8, 0, 9, 4, 0, 1, 1, 3, 5, 0, 3, 9, 4, 2, 2, 8, 5,\n",
            "        0, 9, 0, 2, 3, 1, 1, 0, 8, 9, 2, 1, 9, 6, 3, 0, 1, 7, 3, 5, 2, 8, 6, 3,\n",
            "        6, 7, 3, 0, 4, 1, 9, 1, 4, 3, 7, 4, 2, 2, 3, 4, 1, 0, 5, 3, 7, 2, 7, 3,\n",
            "        5, 6, 7, 1, 1, 7, 4, 9, 7, 6, 5, 1, 0, 6, 4, 1, 2, 0, 1, 1, 3, 4, 8, 6,\n",
            "        8, 3, 4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPFrhT5SO75T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}